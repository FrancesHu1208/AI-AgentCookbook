"""
AutoGen Web Agent Google æœç´¢ç¤ºä¾‹ - åŒ…å«æ–‡ä»¶ä¿å­˜åŠŸèƒ½
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ AutoGen çš„å¤šæ¨¡æ€ç½‘é¡µæµè§ˆä»£ç†è¿›è¡Œ Google æœç´¢ï¼Œå¹¶ä½¿ç”¨ FileSurfer ä¿å­˜ç»“æœ

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†ï¼š
1. å¦‚ä½•è®©ä»£ç†åœ¨ Google ä¸Šæœç´¢ç‰¹å®šæŸ¥è¯¢
2. å¦‚ä½•åˆ†ææœç´¢ç»“æœ
3. å¦‚ä½•æå–æœ‰ç”¨çš„ä¿¡æ¯
4. å¦‚ä½•å¤„ç†å¤šä¸ªæœç´¢ä»»åŠ¡
5. å¦‚ä½•ä½¿ç”¨ FileSurfer ä»£ç†å°†æœç´¢ç»“æœä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
6. å¦‚ä½•åˆ›å»ºç»“æ„åŒ–çš„æŠ¥å‘Šå’Œåˆ†ææ–‡æ¡£
"""

# å¯¼å…¥å¿…è¦çš„ AutoGen æ¨¡å—
from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.ui import Console
from autogen_ext.models.openai import AzureOpenAIChatCompletionClient
from autogen_ext.agents.web_surfer import MultimodalWebSurfer
from autogen_agentchat.teams import MagenticOneGroupChat
from autogen_ext.agents.file_surfer import FileSurfer

import asyncio
import os
from datetime import datetime


def create_output_directory(dir_name: str = "search_results"):
    """
    åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    
    Args:
        dir_name: ç›®å½•åç§°ï¼Œé»˜è®¤ä¸º "search_results"
    
    Returns:
        str: åˆ›å»ºçš„ç›®å½•è·¯å¾„
    """
    import os
    
    if not os.path.exists(dir_name):
        os.makedirs(dir_name)
        print(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {dir_name}")
    else:
        print(f"ğŸ“ ä½¿ç”¨ç°æœ‰ç›®å½•: {dir_name}")
    
    return dir_name


def setup_azure_client():
    """
    è®¾ç½® Azure OpenAI å®¢æˆ·ç«¯
    """
    # é…ç½® Azure OpenAI è¿æ¥å‚æ•°
    endpoint = os.getenv("ENDPOINT_URL", "https://ai-<endpoint>.openai.azure.com/")
    deployment = os.getenv("DEPLOYMENT_NAME", "gpt-4.1")
    api_key = os.getenv("AZURE_API_KEY")
    
    # æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡
    if not api_key:
        raise ValueError("AZURE_API_KEY ç¯å¢ƒå˜é‡å¿…é¡»è®¾ç½®")
    
    # åˆ›å»ºå¹¶è¿”å›æ¨¡å‹å®¢æˆ·ç«¯
    return AzureOpenAIChatCompletionClient(
        model=deployment,
        azure_deployment=deployment,
        api_key=api_key,
        azure_endpoint=endpoint,
        api_version="2024-12-01-preview"
    )


async def google_search_demo():
    """
    Google æœç´¢æ¼”ç¤ºå‡½æ•°
    å±•ç¤ºå¦‚ä½•ä½¿ç”¨ç½‘é¡µä»£ç†è¿›è¡Œæœç´¢å’Œä¿¡æ¯æå–ï¼Œå¹¶ä¿å­˜ç»“æœåˆ°æœ¬åœ°æ–‡ä»¶
    """
    # è®¾ç½®æ¨¡å‹å®¢æˆ·ç«¯
    model_client = setup_azure_client()
    
    # åˆ›å»ºç½‘é¡µæµè§ˆä»£ç†
    web_surfer_agent = MultimodalWebSurfer(
        name="GoogleSearchAgent",  # ç»™ä»£ç†ä¸€ä¸ªæè¿°æ€§çš„åç§°
        model_client=model_client,
        headless=False,  # æ˜¾ç¤ºæµè§ˆå™¨çª—å£ï¼Œæ–¹ä¾¿è§‚å¯Ÿ
        animate_actions=True  # æ˜¾ç¤ºåŠ¨ç”»æ•ˆæœ
    )
    
    # åˆ›å»ºæ–‡ä»¶æ“ä½œä»£ç†
    file_surfer_agent = FileSurfer(
        name="FileManagerAgent",  # æ–‡ä»¶ç®¡ç†ä»£ç†
        model_client=model_client
    )
    
    # åˆ›å»ºåŒ…å«ä¸¤ä¸ªä»£ç†çš„å›¢é˜Ÿ
    agent_team = MagenticOneGroupChat(
        [web_surfer_agent, file_surfer_agent],
        max_turns=25,  # å¢åŠ è½®æ•°ä»¥å¤„ç†æœç´¢å’Œæ–‡ä»¶æ“ä½œ
        model_client=model_client
    )    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = create_output_directory("search_results")
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    try:
        # ä»»åŠ¡ 1: åŸºç¡€ Google æœç´¢å¹¶ä¿å­˜ç»“æœ
        print("ğŸ” å¼€å§‹æ‰§è¡Œä»»åŠ¡ 1: AI ä»£ç†åŸ¹è®­æœç´¢from courseare")
        search_task_1 = f"""
        Go to https://www.coursera.org and search for 'AI Agent Trainings'. 
        Look at the first 5 search results and provide a detailed summary of what each result offers.
        
        After gathering the search results, save the summary to table format, the table include:
        Include:
        - AI Agents Training title
        - URL of the title
        - Date and time of search
        - Detailed summary of each result (title, URL, description)
        - Score and ranking based on relevance and quality
        """
        
        stream_1 = agent_team.run_stream(task=search_task_1)
        await Console(stream_1)
        
        print("\n" + "="*50 + "\n")


        # ä»»åŠ¡ 2: åŸºç¡€ Google æœç´¢å¹¶ä¿å­˜ç»“æœ
        print("ğŸ” å¼€å§‹æ‰§è¡Œä»»åŠ¡ 2: AI ä»£ç†åŸ¹è®­æœç´¢from deeplearning.ai")
        search_task_2 = f"""
        Go to https://www.deeplearning.ai and search for 'AI Agent Trainings'. 
        Look at the first 5 search results and provide a detailed summary of what each result offers.
        
        After gathering the search results, save the summary to table format, the table include:
        Include:
        - AI Agents Training title
        - URL of the title
        - Date and time of search
        - Detailed summary of each result (title, URL, description)
        - Score and ranking based on relevance and quality
        """
        
        stream_2 = agent_team.run_stream(task=search_task_2)
        await Console(stream_2)
        
        print("\n" + "="*50 + "\n")
        
        # ä»»åŠ¡ 2: æŠ€æœ¯æ¯”è¾ƒæœç´¢å¹¶ä¿å­˜ç»“æœ
        print("ğŸ” å¼€å§‹æ‰§è¡Œä»»åŠ¡ 3: AI Agents æ¯”è¾ƒåˆ†æ")
        search_task_3 = f"""
        Based on the results from the first and second searches, find and compare different AI agent training programs.
        Create a comparison table with scores and rankings for different training programs.

        Save the comparison analysis to a table format.
        Include:
        - Comparison criteria
        - Detailed scoring methodology
        - Ranking table of training programs
        - Pros and cons for each program
        - Final recommendations
        """

        stream_3 = agent_team.run_stream(task=search_task_3)
        await Console(stream_3)
        
        print("\n" + "="*50 + "\n")
        
        # ä»»åŠ¡ 3: åˆ›å»ºæ±‡æ€»æŠ¥å‘Š
        print("ğŸ“„ åˆ›å»ºæ±‡æ€»æŠ¥å‘Š")
        summary_task = f"""
        Create a comprehensive summary report that combines the results from both searches.
        
        The report should include:
        - Executive Summary
        - Detailed Findings from both searches
        - Comparison Analysis
        - Recommendations
        - Next Steps
        
        Format it professionally with proper headings, bullet points, and tables.
        """
        
        stream_3 = agent_team.run_stream(task=summary_task)
        await Console(stream_3)        
    except Exception as e:
        print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
    
    finally:
        # ç¡®ä¿å…³é—­æµè§ˆå™¨
        print("ğŸ”’ æ­£åœ¨å…³é—­æµè§ˆå™¨...")
        await web_surfer_agent.close()
        print("âœ… æ‰€æœ‰æœç´¢ä»»åŠ¡å®Œæˆï¼æœç´¢ç»“æœå·²ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ã€‚")


async def targeted_search(query: str, additional_instructions: str = ""):
    """
    æ‰§è¡Œé’ˆå¯¹æ€§æœç´¢çš„è¾…åŠ©å‡½æ•°ï¼Œå¹¶ä¿å­˜ç»“æœåˆ°æœ¬åœ°æ–‡ä»¶
    
    Args:
        query: æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²
        additional_instructions: é¢å¤–çš„æŒ‡ä»¤
    """
    model_client = setup_azure_client()
    
    # åˆ›å»ºç½‘é¡µæµè§ˆä»£ç†
    web_surfer_agent = MultimodalWebSurfer(
        name="TargetedSearchAgent",
        model_client=model_client,
        headless=True,  # é™é»˜æ¨¡å¼ï¼Œæ›´å¿«æ‰§è¡Œ
        animate_actions=False
    )
    
    # åˆ›å»ºæ–‡ä»¶æ“ä½œä»£ç†
    file_surfer_agent = FileSurfer(
        name="FileManagerAgent",
        model_client=model_client
    )
    
    # åˆ›å»ºä»£ç†å›¢é˜Ÿ
    agent_team = MagenticOneGroupChat(
        [web_surfer_agent, file_surfer_agent],
        max_turns=20,
        model_client=model_client
    )
      # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å
    output_dir = create_output_directory("search_results")
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_query = "".join(c for c in query if c.isalnum() or c in (' ', '-', '_')).rstrip()
    safe_query = safe_query.replace(' ', '_')[:50]  # é™åˆ¶æ–‡ä»¶åé•¿åº¦
    filename = f"{output_dir}/targeted_search_{safe_query}_{timestamp}.txt"
    
    # æ„å»ºå®Œæ•´çš„æœç´¢ä»»åŠ¡ï¼ŒåŒ…å«æ–‡ä»¶ä¿å­˜æŒ‡ä»¤
    full_task = f"""
    Go to Google and search for '{query}'. {additional_instructions}
    
    After completing the search and analysis, save the results to a file named '{filename}'.
    Include in the file:
    - Search query: {query}
    - Search timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    - Additional instructions: {additional_instructions}
    - Detailed search results and analysis
    - Your conclusions and recommendations
    """
    
    try:
        print(f"ğŸ” æ‰§è¡Œæœç´¢: {query}")
        print(f"ğŸ“ ç»“æœå°†ä¿å­˜åˆ°: {filename}")
        stream = agent_team.run_stream(task=full_task)
        await Console(stream)
        print(f"âœ… æœç´¢å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ° {filename}")
    finally:
        await web_surfer_agent.close()


async def main():
    """
    ä¸»å‡½æ•° - é€‰æ‹©è¿è¡Œæ¨¡å¼
    """
    print("ğŸŒŸ AutoGen Google æœç´¢ä»£ç†æ¼”ç¤º - åŒ…å«æ–‡ä»¶ä¿å­˜åŠŸèƒ½")
    print("=" * 50)
    print("åŠŸèƒ½ç‰¹ç‚¹ï¼š")
    print("âœ… Google æœç´¢å’Œç»“æœåˆ†æ")
    print("âœ… è‡ªåŠ¨ä¿å­˜æœç´¢ç»“æœåˆ°æœ¬åœ°æ–‡ä»¶")
    print("âœ… ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Šï¼ˆTXT å’Œ Markdown æ ¼å¼ï¼‰")
    print("âœ… æ”¯æŒè‡ªå®šä¹‰æœç´¢æŸ¥è¯¢")
    print("=" * 50)
    
    # å¯ä»¥é€‰æ‹©è¿è¡Œå®Œæ•´æ¼”ç¤ºæˆ–å•ä¸ªæœç´¢
    mode = input("é€‰æ‹©æ¨¡å¼ (1: å®Œæ•´æ¼”ç¤º, 2: å•ä¸ªæœç´¢, 3: æŸ¥çœ‹å·²ä¿å­˜æ–‡ä»¶): ").strip()
    
    if mode == "1":
        await google_search_demo()
    elif mode == "2":
        query = input("è¾“å…¥æœç´¢æŸ¥è¯¢: ").strip()
        instructions = input("è¾“å…¥é¢å¤–æŒ‡ä»¤ (å¯é€‰): ").strip()
        await targeted_search(query, instructions)
    elif mode == "3":
        show_saved_files()
    else:
        print("æ— æ•ˆé€‰æ‹©ï¼Œè¿è¡Œå®Œæ•´æ¼”ç¤º...")
        await google_search_demo()


def show_saved_files():
    """
    æ˜¾ç¤ºå·²ä¿å­˜çš„æœç´¢ç»“æœæ–‡ä»¶
    """
    import os
    import glob
    
    output_dir = "search_results"
    if not os.path.exists(output_dir):
        print(f"âŒ ç›®å½• '{output_dir}' ä¸å­˜åœ¨ã€‚")
        return
    
    # æŸ¥æ‰¾æ‰€æœ‰ä¿å­˜çš„æ–‡ä»¶
    txt_files = glob.glob(f"{output_dir}/*.txt")
    md_files = glob.glob(f"{output_dir}/*.md")
    
    if not txt_files and not md_files:
        print(f"ğŸ“ ç›®å½• '{output_dir}' ä¸­æ²¡æœ‰æ‰¾åˆ°ä¿å­˜çš„æ–‡ä»¶ã€‚")
        return
    
    print(f"ğŸ“ åœ¨ '{output_dir}' ç›®å½•ä¸­æ‰¾åˆ°ä»¥ä¸‹æ–‡ä»¶ï¼š")
    print("-" * 40)
    
    if txt_files:
        print("ğŸ“„ æ–‡æœ¬æ–‡ä»¶ (.txt):")
        for file in sorted(txt_files):
            file_size = os.path.getsize(file)
            mod_time = os.path.getmtime(file)
            mod_time_str = datetime.fromtimestamp(mod_time).strftime('%Y-%m-%d %H:%M:%S')
            print(f"  â€¢ {os.path.basename(file)} ({file_size} å­—èŠ‚, {mod_time_str})")
    
    if md_files:
        print("ğŸ“ Markdown æ–‡ä»¶ (.md):")
        for file in sorted(md_files):
            file_size = os.path.getsize(file)
            mod_time = os.path.getmtime(file)
            mod_time_str = datetime.fromtimestamp(mod_time).strftime('%Y-%m-%d %H:%M:%S')
            print(f"  â€¢ {os.path.basename(file)} ({file_size} å­—èŠ‚, {mod_time_str})")
    
    print("-" * 40)
    print(f"ğŸ“Š æ€»è®¡: {len(txt_files)} ä¸ª TXT æ–‡ä»¶, {len(md_files)} ä¸ª MD æ–‡ä»¶")


if __name__ == "__main__":
    """
    ç¨‹åºå…¥å£ç‚¹
    """
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­äº†ç¨‹åºæ‰§è¡Œ")
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
